{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "* similar to NumPy's ndarrays\n",
    "* pytorch tensors can accerlerate GPG computing\n",
    "* ```  torch.syntax(x, y) ```\n",
    "\n",
    "---\n",
    "\n",
    "- [ ] what is dtype\n",
    "- [ ] what is a tuple operator\n",
    "\n",
    "---\n",
    "\n",
    "-- [blitz](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 1.4013e-45, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.1704e-41, 0.0000e+00, 2.2369e+08],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "\n",
    "# 5 x 3 matrix, uninitialized\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0925, 0.8708, 0.6124],\n",
      "        [0.4057, 0.2797, 0.5092],\n",
      "        [0.9871, 0.6832, 0.6578],\n",
      "        [0.4032, 0.2646, 0.8911],\n",
      "        [0.2479, 0.2078, 0.0879]])\n"
     ]
    }
   ],
   "source": [
    "# random initialized matrix\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# zeros, dtype long matrix\n",
    "x = torch.zeros(5, 3, dtype = torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# tensor directly from data\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "\n",
      "tensor([[-0.4090,  0.5867,  1.2171],\n",
      "        [-0.6665,  0.9825,  0.5570],\n",
      "        [-1.0807,  0.3264,  0.1208],\n",
      "        [ 0.9368,  2.9475,  0.4683],\n",
      "        [ 1.0758,  0.2566, -0.2496]])\n",
      "\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# new tensor, from tensor\n",
    "\n",
    "# dtype = new size\n",
    "x = x.new_ones(5, 3, dtype = torch.double)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "# new dtype = x inputs randomized\n",
    "# matrix still same size\n",
    "x = torch.randn_like(x, dtype = torch.float)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "# torch.size = tuple operator\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + y :\n",
      "tensor([[2.7497, 2.7621, 2.7812],\n",
      "        [2.3754, 2.6857, 2.2906],\n",
      "        [2.6309, 2.2168, 2.5430],\n",
      "        [2.3221, 2.3671, 1.9226],\n",
      "        [2.7480, 2.0740, 1.9840]])\n",
      "\n",
      "torch.add(x, y) :\n",
      "tensor([[2.7497, 2.7621, 2.7812],\n",
      "        [2.3754, 2.6857, 2.2906],\n",
      "        [2.6309, 2.2168, 2.5430],\n",
      "        [2.3221, 2.3671, 1.9226],\n",
      "        [2.7480, 2.0740, 1.9840]])\n",
      "\n",
      "result :\n",
      "tensor([[2.7497, 2.7621, 2.7812],\n",
      "        [2.3754, 2.6857, 2.2906],\n",
      "        [2.6309, 2.2168, 2.5430],\n",
      "        [2.3221, 2.3671, 1.9226],\n",
      "        [2.7480, 2.0740, 1.9840]])\n",
      "\n",
      "y :\n",
      "tensor([[2.7497, 2.7621, 2.7812],\n",
      "        [2.3754, 2.6857, 2.2906],\n",
      "        [2.6309, 2.2168, 2.5430],\n",
      "        [2.3221, 2.3671, 1.9226],\n",
      "        [2.7480, 2.0740, 1.9840]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# syntax 01\n",
    "y = torch.rand(5, 3)\n",
    "print('x + y :')\n",
    "print(x + y)\n",
    "print()\n",
    "\n",
    "\n",
    "# syntax 02\n",
    "print('torch.add(x, y) :')\n",
    "print(torch.add(x, y))\n",
    "print()\n",
    "\n",
    "# arg\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out = result)\n",
    "print('result :')\n",
    "print(result)\n",
    "print()\n",
    "\n",
    "# mutate tensor 'x' with x.copy_(y), x.t_()\n",
    "y.add_(x)\n",
    "print('y :')\n",
    "print(y)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-81938c0e2c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# index using standard numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Numpy index x[:, 1] :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# index using standard numpy\n",
    "print('Numpy index x[:, 1] :', x [:, 1])\n",
    "print() \n",
    "\n",
    "\n",
    "# resize/reshape tensor with 'torch.view'\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "# -1 infers another dimension\n",
    "print('resize/reshape tensor with \"x.view\" :', x.size(), y.size(), z.size())\n",
    "print()\n",
    "\n",
    "\n",
    "# get py number for one element tensor with 'x.item()'\n",
    "x = torch.randn(1)\n",
    "print('x : ', x)\n",
    "print('one element tensor as py number x.item() : ', x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Bridge\n",
    "\n",
    "* convert torch tensor into numpy array\n",
    "* memory locations shared\n",
    "\n",
    "##### Convert Torch Tensor to NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# tensor\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# numpy\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = torch.ones(5) : tensor([3., 3., 3., 3., 3.])\n",
      "b = a.numpy() : [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# change np array value to test\n",
    "a.add_(1)\n",
    "print('a = torch.ones(5) :', a)\n",
    "print('b = a.numpy() :', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert NumPy Array to Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy array\n",
    "a = np.ones(5)\n",
    "# torch\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out = a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA Tensors\n",
    "* move tensors onto any device with ```.to``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "# if available, move tensor from one GPU device to another with 'torch.device' object\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # device = cuda object\n",
    "    device = torch.device('cuda')\n",
    "    # create new tensor on GPU device\n",
    "    y = torch.ones_like(x, device = device)\n",
    "    # to cuda device\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))\n",
    "    \n",
    "# Total running time of the script should be 0 minutes 6.500 seconds, if cuda available\n",
    "# https://is.gd/1hW75p\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGrad\n",
    "\n",
    "##### Automatic Differentiation\n",
    "\n",
    "* vector(v)-Jacobian (matrix) product ( vT ‚ãÖ J ) a row vector, ( JT ‚ãÖ v ) a column vector === easy to feed external gradients into non-scalar output model\n",
    "* v = gradient of scalar function ->  v = ( ‚àÇùìÅ / ‚àÇy‚ÇÅ ‚ãØ ‚àÇùìÅ / ‚àÇym ) T  -> ùìÅ = g ( ‚Éóy )\n",
    "* nn pkg\n",
    "* ``` torch.Tensor ```\n",
    "* don't need gradient computing when evaluating model with trainable parameters (``` requires_grad = True ```)\n",
    "\n",
    "Class Commands\n",
    "\n",
    "* ``` .tensor ``` == function as ``` .grad_fn ``` = creates acyclic graph & encodes computational history\n",
    "    * ``` .grad_fn ``` = function attribute inside tensor\n",
    "* ``` .requires_grad = True ``` = tracks all operations \n",
    "* ``` .backward() ``` = auto computes gradient derivatives from tensor\n",
    "    * no (arguments) if a scalar (one element data tensor)\n",
    "    * matching array/tensor shape in gradient argument if 2+ element data in tensor\n",
    "* ``` .grad ``` = holds tensor (array) values\n",
    "* ``` .detach() ``` = stop tracking operations immediately & completely\n",
    "* ``` with torch.no_grad(): ``` = prevent tracking & memory use\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "\n",
    "#(rows, cols)\n",
    "\n",
    "# create tensor & track computation\n",
    "x = torch.ones(2, 2, requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y : tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "y.grad_fn : <AddBackward0 object at 0x10efb5f60>\n",
      "\n",
      "z : tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "out :  tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# y tensor operation = array function\n",
    "y = x + 2\n",
    "print('y :', y)\n",
    "print()\n",
    "\n",
    "# compute y gradient\n",
    "print('y.grad_fn :', y.grad_fn)\n",
    "print()\n",
    "\n",
    "# calculate mean inside y as a function\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print('z :', z)\n",
    "print('out : ', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.] a = torch.randn(2, 2) : tensor([[ 1.4067,  1.5736],\n",
      "        [-0.6415,  0.8988]])\n",
      "\n",
      "2.] a = ((a * 3) / (a -1)) : tensor([[ 10.3768,   8.2304],\n",
      "        [  1.1724, -26.6577]])\n",
      "\n",
      "3.] a.requires_grad : False\n",
      "\n",
      "4.] a.requires_grad_(True) : tensor([[ 10.3768,   8.2304],\n",
      "        [  1.1724, -26.6577]], requires_grad=True)\n",
      "\n",
      "5.] a.requires_grad : True\n",
      "\n",
      "6.] b = (a * a).sum() : tensor(887.4255, grad_fn=<SumBackward0>)\n",
      "\n",
      "7.] b.grad_fn : <SumBackward0 object at 0x10efc59b0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "print('1.] a = torch.randn(2, 2) :', a)\n",
    "print()\n",
    "\n",
    "a = ((a * 3) / (a -1))\n",
    "print('2.] a = ((a * 3) / (a -1)) :', a)\n",
    "print()\n",
    "\n",
    "print('3.] a.requires_grad :', a.requires_grad)\n",
    "print()\n",
    "\n",
    "a.requires_grad_(True)\n",
    "\n",
    "print('4.] a.requires_grad_(True) :', a.requires_grad_(True))\n",
    "print()\n",
    "\n",
    "print('5.] a.requires_grad :', a.requires_grad)\n",
    "print()\n",
    "\n",
    "b = (a * a).sum()\n",
    "print('6.] b = (a * a).sum() :', b)\n",
    "print()\n",
    "\n",
    "# tensor function\n",
    "print('7.] b.grad_fn :', b.grad_fn)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients: \n",
    "\n",
    "* backloop / back-propragation\n",
    "* d(out) / dx, where ```o``` = ‚Éóy =f( ‚Éóx ) (vector valued function) = Jacobian Matrix\n",
    "\\begin{split}J=\\left(\\begin{array}{ccc}\n",
    " \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    " \\vdots & \\ddots & \\vdots\\\\\n",
    " \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    " \\end{array}\\right)\\end{split} ‚Üí  \\begin{split}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n",
    " \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
    " \\vdots & \\ddots & \\vdots\\\\\n",
    " \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    " \\end{array}\\right)\\left(\\begin{array}{c}\n",
    " \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
    " \\vdots\\\\\n",
    " \\frac{\\partial l}{\\partial y_{m}}\n",
    " \\end{array}\\right)=\\left(\\begin{array}{c}\n",
    " \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
    " \\vdots\\\\\n",
    " \\frac{\\partial l}{\\partial x_{n}}\n",
    " \\end{array}\\right)\\end{split}\n",
    "* linear regression ??\n",
    "* ``` out() ``` = single scalar\n",
    "* ``` out.backward(torch.tensor(1.)) ``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2+ element data in tensor\n",
    "# out.backward()\n",
    "\n",
    "# print gradient of d(out) / dx\n",
    "# print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = vector-Jacobian product\n",
    "\n",
    "x = torch.randn(3, requires_grad = True)\n",
    "print('torch.randn(3, requires_grad = True) :')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "y = x * 2\n",
    "print('y = x * 2 :', y)\n",
    "\n",
    "while y.data.norm() < 1000:\n",
    "    # print(y.data.norm())\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
